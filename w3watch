#!/usr/bin/env bash
# Dependencies:
#   bash, coreutils, diffutils, curl, lynx

DRYRUN=false
VERBOSE=true
SCRIPT=${0##*/}
CONFIG_DIR=${XDG_CONFIG_HOME:-$HOME/.config}/$SCRIPT
CACHE_DIR=$CONFIG_DIR/cache
LOCK_FILE=/tmp/$SCRIPT.lock
WATCHLIST=$CONFIG_DIR/watchlist
BROWSER_CMD='lynx --connect_timeout 10 --read_timeout 10 -stderr -dump -nonumbers'

usage() {
	while read -r; do
		printf '%b\n' "$REPLY"
	done <<-EOF
		\rUsage: $SCRIPT [OPT]

		\r  -e    - Edit watchlist with \$EDITOR
		\r  -l    - List watchlist
		\r  -d    - Dump output and discard any changes
		\r  -c    - Check for updates (Default)
		\r  -h    - Display this help information
		\r
	EOF
	exit 1
}

if [ ! -r "$WATCHLIST" ]; then
	mkdir -p "$CACHE_DIR"

	while read -r; do
		printf '%s\n' "$REPLY"
	done <<-EOF > "$WATCHLIST"
		# $SCRIPT watchlist
		#
		# * Lines starting with a # will be ignored
		# * Every line contains one URL
		# * An optional filter can be defined by separating any command
		#   from the url using whitspaces
		# * Prepend an @ to the URL to work on bare HTML source
		#
		# Example:
		#
		# Watch a complete web page:
		#http://www.archlinux.org
		#
		# You are only interested in xorg related updates?
		# Pipe the page through a grep command.
		#http://www.archlinux.org	grep -i 'xorg'
		#
		# Note: You can use any command which accepts a website dump on stdin and
		#       prints its filtered output to stdout
		#
	EOF

	printf '%b\n\n' ":: Sample watchlist file created at '$WATCHLIST'.
		\r:: You can add URLs to this file and run the script again to initiate the watch."
	usage
	exit 1
fi

[ ! -d "$CACHE_DIR" ] && mkdir -p "$CACHE_DIR"

list() {
	while read -r; do
		[[ ! $REPLY =~ ^\#.* ]] && printf '%s\n' "$REPLY"
	done < "$WATCHLIST"
}

differ() {
	LastMod=$(stat -c '%y' "$1")
	diff --color=auto -u \
		--label "Changes from $LastMod" "$1" \
		--label "$2" -
	ret=$?

	case $ret in
		1) printf '\n' ;;
		0) $VERBOSE && printf ':: \e[3m%s\e[0m\n' "No changes for '$2' since ${LastMod%.*}" ;;
	esac

	return $ret
}

check() {
	if [ -e "$LOCK_FILE" ]; then
		printf '%s\n' "$SCRIPT is locked by $LOCK_FILE"
		exit 1
	else
		touch "$LOCK_FILE"
	fi

	while read -r Line; do
		if [[ ! $Line =~ ^\#.* ]]; then
			data=($Line)
			url=${data[0]}
			filter=${data[*]:1}

			if [[ $url =~ ^@.* ]]; then
				url=${url:1}
				dump=$(curl -Ls "$url")
			else
				dump=$($BROWSER_CMD "$url" 2>/dev/null)
			fi
			ret=$?

			if [ $ret -ne 0 ]; then
				printf '\e[3;31m%s\e[0m\n' ":: Failed to connect to '$url'" >&2
				continue
			fi

			# Pipe output to a command if specified
			if [ -n "$filter" ]; then
				FLine="${data[0]} | $filter"
				dump=$(eval "$filter" <<< "$dump")
			fi

			if $DRYRUN; then
				printf '\e[3;35m%s\e[0m\n%s\n\n' \
					":: Dumping output of '$FLine'" "$dump"
			else
				sum=$(sha1sum <<< "$Line")
				sum=${sum%% *}
				watchlistSums+=("$sum") # to compare later

				cachefile="$CACHE_DIR/$sum"

				if [ -f "$cachefile" ]; then
					differ "$cachefile" "$url" <<< "$dump" ||
						printf '%s\n' "$dump" > "$cachefile"
				else
					printf '%s\n' "$dump" > "$cachefile"
					$VERBOSE && printf ':: \e[3m%s\e[0m\n' \
						"Added '$url' to the watchlist"
				fi
			fi
		fi
	done < "$WATCHLIST"
}

collectGarbage() {
	# Collect checksums from cache files
	for cacheEntry in "$CACHE_DIR/"*; do
		cacheSums+=("${cacheEntry##*/}")
	done

	# Compare cache checksums against watchlist's to find orphans
	for cacheEntry in "${cacheSums[@]}"; do
		skip=
		for watchlistEntry in "${watchlistSums[@]}"; do
			[ "$cacheEntry" = "$watchlistEntry" ] && { skip=1; break; }
		done
		[ -n "$skip" ] || garbage+=("$cacheEntry")
	done

	for garbage in "${garbage[@]}"; do
		rm -f "$CACHE_DIR/$garbage"
	done
}

# Remove $LOCK_FILE on exit/interrupt
trap 'rm -f "$LOCK_FILE"' INT EXIT QUIT ABRT TERM

case $1 in
	-e) $EDITOR "$WATCHLIST" ;;
	-l) list; exit 0 ;;
	-d) DRYRUN=true check ;;
	-c|"") check; collectGarbage ;;
	-h) usage ;;
	*) printf '%s\n\n' "Incorrect option(s) specified."; usage; exit 1 ;;
esac

